{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91ec0d83-31c3-4e4b-9298-2c2c666b1412",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Enable MLflow Tracing for GenAI Development"
    }
   },
   "outputs": [],
   "source": [
    "###  It is highly recommended that you enable MLflow Tracing when developing GenAI applications. Tracing provides a step-by-step analysis of your app's execution, helping you debug latency, cost, and quality issues. Traces can be used with Agent Evaluation to measure your app's quality, and the same Trace will be automatically captured once you deploy your application.\n",
    "\n",
    "\n",
    "%pip install -U mlflow\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "257a261f-11e6-47ad-9f6b-0be1a64d13a3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Autologging OpenAI with MLflow"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.openai.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9607211b-19fd-4a71-bc61-a595a9acda49",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Retrieve OpenAI response with Databricks token"
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# How to get your Databricks token: https://docs.databricks.com/en/dev-tools/auth/pat.html\n",
    "DATABRICKS_TOKEN = os.environ.get('DATABRICKS_TOKEN')\n",
    "# Alternatively in a Databricks notebook you can use this:\n",
    "# DATABRICKS_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=DATABRICKS_TOKEN or os.environ['OPENAI_API_KEY'],\n",
    "    base_url=\"https://adb-1098933906466604.4.azuredatabricks.net/serving-endpoints\"\n",
    ")\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"mas-01875d0e-endpoint\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What are the emerging investment themes mentioned in the market research documents?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.output[0].content[0].text)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "OpenAI LLM Agent Inquiry",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
