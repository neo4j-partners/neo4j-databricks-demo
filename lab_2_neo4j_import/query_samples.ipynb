{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Graph Query Samples\n",
    "\n",
    "This notebook contains sample Cypher queries for analyzing the retail banking and investment portfolio graph using the **Neo4j Spark Connector**.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. Run `import_financial_data_to_neo4j.ipynb` first to load the data\n",
    "2. Databricks Secrets configured with `neo4j-creds` scope\n",
    "3. Neo4j Spark Connector installed on the cluster\n",
    "\n",
    "## Best Practices Used\n",
    "\n",
    "- **Spark DataSource V2 API** for all Neo4j operations\n",
    "- **Pushdown optimizations** enabled by default (filters, columns, aggregates, limits)\n",
    "- **Partitioning** for parallel reads on large result sets\n",
    "- **Query mode** for complex Cypher patterns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SPARK CONNECTOR CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Loading Neo4j credentials from Databricks Secrets...\")\n",
    "\n",
    "NEO4J_URL = dbutils.secrets.get(scope=\"neo4j-creds\", key=\"url\")\n",
    "NEO4J_USER = dbutils.secrets.get(scope=\"neo4j-creds\", key=\"username\")\n",
    "NEO4J_PASS = dbutils.secrets.get(scope=\"neo4j-creds\", key=\"password\")\n",
    "NEO4J_DATABASE = \"neo4j\"\n",
    "\n",
    "# Configure Spark session for Neo4j Connector\n",
    "# These settings apply to all subsequent reads/writes\n",
    "spark.conf.set(\"neo4j.url\", NEO4J_URL)\n",
    "spark.conf.set(\"neo4j.authentication.type\", \"basic\")\n",
    "spark.conf.set(\"neo4j.authentication.basic.username\", NEO4J_USER)\n",
    "spark.conf.set(\"neo4j.authentication.basic.password\", NEO4J_PASS)\n",
    "spark.conf.set(\"neo4j.database\", NEO4J_DATABASE)\n",
    "\n",
    "print(f\"Neo4j URL: {NEO4J_URL}\")\n",
    "print(f\"Database: {NEO4J_DATABASE}\")\n",
    "print(\"Spark session configured for Neo4j Connector.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HELPER FUNCTION FOR CYPHER QUERIES\n",
    "# =============================================================================\n",
    "\n",
    "def run_query(query: str, partitions: int = 1):\n",
    "    \"\"\"\n",
    "    Execute a Cypher query using the Neo4j Spark Connector.\n",
    "    \n",
    "    Args:\n",
    "        query: Cypher query string\n",
    "        partitions: Number of partitions for parallel reads (default: 1)\n",
    "                   Use higher values for large result sets\n",
    "    \n",
    "    Returns:\n",
    "        Spark DataFrame with query results\n",
    "    \n",
    "    Note: Pushdown optimizations are enabled by default:\n",
    "        - pushdown.filters.enabled = true\n",
    "        - pushdown.columns.enabled = true  \n",
    "        - pushdown.aggregate.enabled = true\n",
    "        - pushdown.limit.enabled = true (disabled when partitions > 1)\n",
    "    \"\"\"\n",
    "    return (\n",
    "        spark.read\n",
    "        .format(\"org.neo4j.spark.DataSource\")\n",
    "        .option(\"query\", query)\n",
    "        .option(\"partitions\", str(partitions))\n",
    "        .load()\n",
    "    )\n",
    "\n",
    "# Test connection\n",
    "test_df = run_query(\"RETURN 'Connected!' AS status\")\n",
    "print(f\"Connection: {test_df.collect()[0]['status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Portfolio Analysis\n",
    "\n",
    "Analyze customer investment portfolios across the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# Total Portfolio Value by Customer\n# =============================================================================\nprint(\"Top 10 Customers by Total Portfolio Value\")\nprint(\"=\" * 50)\n\n# Best Practice: Use explicit WITH clause for aggregation grouping\nquery = \"\"\"\nMATCH (c:Customer)-[:HAS_ACCOUNT]->(a:Account)-[:HAS_POSITION]->(p:Position)\nWITH c, round(SUM(p.current_value), 2) AS total_portfolio_value\nRETURN\n    c.customer_id AS customer_id,\n    c.first_name + ' ' + c.last_name AS customer_name,\n    total_portfolio_value\nORDER BY total_portfolio_value DESC\nLIMIT 10\n\"\"\"\n\ndisplay(run_query(query))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Accounts with Multiple Positions (Diversified Portfolios)\n",
    "# =============================================================================\n",
    "print(\"Accounts with Multiple Holdings\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "query = \"\"\"\n",
    "MATCH (a:Account)-[:HAS_POSITION]->(p:Position)\n",
    "WITH a, COUNT(p) AS position_count, round(SUM(p.current_value), 2) AS total_value\n",
    "WHERE position_count > 1\n",
    "RETURN\n",
    "    a.account_id AS account,\n",
    "    a.account_type AS type,\n",
    "    position_count AS num_positions,\n",
    "    total_value AS portfolio_value\n",
    "ORDER BY position_count DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "display(run_query(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# Sector Allocation Analysis\n# =============================================================================\nprint(\"Investment Allocation by Sector\")\nprint(\"=\" * 50)\n\n# Best Practice: Filter NULL values before sorting\nquery = \"\"\"\nMATCH (a:Account)-[:HAS_POSITION]->(p:Position)-[:OF_SECURITY]->(s:Stock)-[:OF_COMPANY]->(c:Company)\nWHERE c.sector IS NOT NULL\nWITH c.sector AS sector, round(SUM(p.current_value), 2) AS sector_value\nWITH sector, sector_value, SUM(sector_value) OVER () AS total_value\nRETURN\n    sector,\n    sector_value,\n    round(sector_value * 100.0 / total_value, 2) AS pct_of_total\nORDER BY sector_value DESC\n\"\"\"\n\ndisplay(run_query(query))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Stock Diversification by Account\n",
    "# =============================================================================\n",
    "print(\"Sector Diversification Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "query = \"\"\"\n",
    "MATCH (a:Account)-[:HAS_POSITION]->(p:Position)-[:OF_SECURITY]->(s:Stock)-[:OF_COMPANY]->(c:Company)\n",
    "WITH a, \n",
    "     COUNT(DISTINCT c.sector) AS num_sectors,\n",
    "     COLLECT(DISTINCT c.sector) AS sectors,\n",
    "     round(SUM(p.current_value), 2) AS total_portfolio_value\n",
    "RETURN\n",
    "    a.account_id AS account,\n",
    "    num_sectors,\n",
    "    sectors,\n",
    "    total_portfolio_value\n",
    "ORDER BY num_sectors DESC, total_portfolio_value DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "display(run_query(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Transaction Network Analysis\n",
    "\n",
    "Analyze money flow patterns across the transaction network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Accounts with Most Outbound Transactions\n",
    "# =============================================================================\n",
    "print(\"Most Active Sending Accounts\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "query = \"\"\"\n",
    "MATCH (a:Account)-[:PERFORMS]->(t:Transaction)\n",
    "WITH a, COUNT(t) AS tx_count, round(SUM(t.amount), 2) AS total_sent\n",
    "ORDER BY tx_count DESC\n",
    "LIMIT 10\n",
    "MATCH (c:Customer)-[:HAS_ACCOUNT]->(a)\n",
    "RETURN\n",
    "    c.first_name + ' ' + c.last_name AS customer_name,\n",
    "    a.account_id AS account,\n",
    "    a.account_type AS account_type,\n",
    "    tx_count AS num_transactions,\n",
    "    total_sent\n",
    "\"\"\"\n",
    "\n",
    "display(run_query(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Accounts That Both Send and Receive Transactions\n",
    "# =============================================================================\n",
    "print(\"Accounts with Bidirectional Transaction Flow\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "query = \"\"\"\n",
    "MATCH (a:Account)-[:PERFORMS]->(:Transaction)\n",
    "WITH a, COUNT(*) AS sent_count\n",
    "MATCH (a)<-[:BENEFITS_TO]-(:Transaction)\n",
    "WITH a, sent_count, COUNT(*) AS received_count\n",
    "MATCH (c:Customer)-[:HAS_ACCOUNT]->(a)\n",
    "RETURN\n",
    "    c.first_name + ' ' + c.last_name AS customer_name,\n",
    "    a.account_id AS account,\n",
    "    a.account_type AS type,\n",
    "    a.balance AS balance,\n",
    "    sent_count,\n",
    "    received_count\n",
    "ORDER BY sent_count + received_count DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "display(run_query(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# High-Value Transactions\n",
    "# =============================================================================\n",
    "print(\"High-Value Transactions (> $1,000)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "query = \"\"\"\n",
    "MATCH (from:Account)-[:PERFORMS]->(t:Transaction)-[:BENEFITS_TO]->(to:Account)\n",
    "WHERE t.amount > 1000\n",
    "RETURN\n",
    "    from.account_id AS sender,\n",
    "    to.account_id AS recipient,\n",
    "    t.amount AS amount,\n",
    "    t.transaction_date AS date,\n",
    "    t.description AS description\n",
    "ORDER BY t.amount DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "display(run_query(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Transaction Status Summary\n",
    "# =============================================================================\n",
    "print(\"Transaction Status Distribution\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "query = \"\"\"\n",
    "MATCH (t:Transaction)\n",
    "RETURN t.status AS status, COUNT(t) AS count, round(SUM(t.amount), 2) AS total_amount\n",
    "ORDER BY count DESC\n",
    "\"\"\"\n",
    "\n",
    "display(run_query(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Risk Profile Analysis\n",
    "\n",
    "Segment customers and analyze behavior by risk profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# Risk Profile Segmentation\n# =============================================================================\nprint(\"Portfolio Characteristics by Risk Profile\")\nprint(\"=\" * 50)\n\n# Best Practice: Filter NULL values before sorting\nquery = \"\"\"\nMATCH (c:Customer)-[:HAS_ACCOUNT]->(a:Account)\nWHERE c.risk_profile IS NOT NULL\nOPTIONAL MATCH (a)-[:HAS_POSITION]->(p:Position)\nWITH c.risk_profile AS risk_profile,\n     COUNT(DISTINCT c) AS num_customers,\n     AVG(c.annual_income) AS avg_income,\n     AVG(c.credit_score) AS avg_credit_score,\n     AVG(a.balance) AS avg_account_balance,\n     SUM(p.current_value) AS total_investment_value\nRETURN\n    risk_profile,\n    num_customers,\n    round(avg_income, 0) AS avg_income,\n    round(avg_credit_score, 0) AS avg_credit_score,\n    round(avg_account_balance, 2) AS avg_account_balance,\n    round(total_investment_value, 2) AS total_investment_value\nORDER BY risk_profile\n\"\"\"\n\ndisplay(run_query(query))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Reading Nodes and Relationships Directly\n",
    "\n",
    "The Spark Connector can also read nodes and relationships directly without custom Cypher queries. This enables automatic pushdown optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Read Nodes by Label with Pushdown\n",
    "# =============================================================================\n",
    "print(\"Reading Customer Nodes (with automatic pushdown)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Read all Customer nodes - Spark handles pushdown automatically\n",
    "customers_df = (\n",
    "    spark.read\n",
    "    .format(\"org.neo4j.spark.DataSource\")\n",
    "    .option(\"labels\", \"Customer\")\n",
    "    .load()\n",
    ")\n",
    "\n",
    "# Filter and select - these operations are pushed down to Neo4j\n",
    "high_income_customers = (\n",
    "    customers_df\n",
    "    .filter(\"annual_income > 100000\")\n",
    "    .filter(\"credit_score > 700\")\n",
    "    .select(\"customer_id\", \"first_name\", \"last_name\", \"annual_income\", \"credit_score\", \"risk_profile\")\n",
    "    .orderBy(\"annual_income\", ascending=False)\n",
    "    .limit(10)\n",
    ")\n",
    "\n",
    "display(high_income_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Read Relationships Directly\n",
    "# =============================================================================\n",
    "print(\"Reading HAS_ACCOUNT Relationships\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Read relationships with source and target node properties\n",
    "has_account_df = (\n",
    "    spark.read\n",
    "    .format(\"org.neo4j.spark.DataSource\")\n",
    "    .option(\"relationship\", \"HAS_ACCOUNT\")\n",
    "    .option(\"relationship.source.labels\", \"Customer\")\n",
    "    .option(\"relationship.target.labels\", \"Account\")\n",
    "    .load()\n",
    ")\n",
    "\n",
    "print(f\"Schema: {has_account_df.columns}\")\n",
    "display(has_account_df.limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exporting Query Results to Delta Lake\n",
    "\n",
    "A common pattern is to run graph queries and store results in Delta tables for downstream analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# Export Graph Analytics to Delta Table (Example)\n# =============================================================================\nprint(\"Exporting Portfolio Summary to Delta (example pattern)\")\nprint(\"=\" * 50)\n\n# Query aggregated portfolio data from Neo4j\n# Best Practice: Use explicit WITH for aggregation and handle NULL sort values\nportfolio_query = \"\"\"\nMATCH (c:Customer)-[:HAS_ACCOUNT]->(a:Account)\nOPTIONAL MATCH (a)-[:HAS_POSITION]->(p:Position)-[:OF_SECURITY]->(s:Stock)-[:OF_COMPANY]->(co:Company)\nWITH c,\n     COUNT(DISTINCT a) AS num_accounts,\n     SUM(a.balance) AS total_balance,\n     COUNT(DISTINCT p) AS num_positions,\n     SUM(p.current_value) AS total_investments,\n     COLLECT(DISTINCT co.sector) AS sectors\nRETURN\n    c.customer_id AS customer_id,\n    c.first_name + ' ' + c.last_name AS customer_name,\n    c.risk_profile AS risk_profile,\n    num_accounts,\n    round(total_balance, 2) AS total_balance,\n    num_positions,\n    round(coalesce(total_investments, 0), 2) AS total_investments,\n    SIZE(sectors) AS num_sectors\nORDER BY total_investments DESC NULLS LAST\n\"\"\"\n\nportfolio_df = run_query(portfolio_query)\ndisplay(portfolio_df.limit(10))\n\n# Uncomment to write to Delta:\n# portfolio_df.write \\\n#     .format(\"delta\") \\\n#     .mode(\"overwrite\") \\\n#     .saveAsTable(\"gold.customer_portfolio_summary\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Graph Visualization Queries\n",
    "\n",
    "Queries designed for visual exploration in Neo4j Browser or Bloom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Customer Financial Network (for Neo4j Browser)\n",
    "# =============================================================================\n",
    "print(\"Customer C0001's Complete Financial Network\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\")\n",
    "print(\"Run this query in Neo4j Browser for visual exploration:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "viz_query = \"\"\"\n",
    "MATCH path = (c:Customer {customer_id: 'C0001'})-[*1..3]-(connected)\n",
    "RETURN path\n",
    "LIMIT 50\n",
    "\"\"\"\n",
    "\n",
    "print(viz_query)\n",
    "print(\"-\" * 50)\n",
    "print(\"\")\n",
    "\n",
    "# Show node counts for context\n",
    "count_query = \"\"\"\n",
    "MATCH (c:Customer {customer_id: 'C0001'})-[r*1..3]-(connected)\n",
    "RETURN labels(connected)[0] AS node_type, COUNT(DISTINCT connected) AS count\n",
    "ORDER BY count DESC\n",
    "\"\"\"\n",
    "\n",
    "print(\"Connected nodes:\")\n",
    "display(run_query(count_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Transaction Flow Visualization (for Neo4j Browser)\n",
    "# =============================================================================\n",
    "print(\"Transaction Flow Network\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\")\n",
    "print(\"Run this query in Neo4j Browser for visual exploration:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "viz_query = \"\"\"\n",
    "MATCH path = (from:Account)-[:PERFORMS]->(t:Transaction)-[:BENEFITS_TO]->(to:Account)\n",
    "RETURN path\n",
    "LIMIT 25\n",
    "\"\"\"\n",
    "\n",
    "print(viz_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Query Summary\n",
    "\n",
    "This notebook demonstrated using the **Neo4j Spark Connector** for:\n",
    "\n",
    "**Portfolio Analysis**\n",
    "- Total portfolio value by customer\n",
    "- Accounts with diversified holdings\n",
    "- Sector allocation breakdown\n",
    "- Sector diversification per account\n",
    "\n",
    "**Transaction Network**\n",
    "- Most active sending accounts\n",
    "- Bidirectional transaction flow\n",
    "- High-value transactions\n",
    "- Transaction status distribution\n",
    "\n",
    "**Risk Analysis**\n",
    "- Customer segmentation by risk profile\n",
    "\n",
    "**Connector Patterns**\n",
    "- Reading nodes by label with automatic pushdown\n",
    "- Reading relationships with source/target properties\n",
    "- Exporting to Delta Lake\n",
    "\n",
    "**Visualization**\n",
    "- Customer financial network paths\n",
    "- Transaction flow patterns\n",
    "\n",
    "### Best Practices Applied\n",
    "\n",
    "1. **Use `query` option** for complex Cypher with multiple MATCH clauses\n",
    "2. **Use `labels` option** for simple node reads (enables automatic pushdown)\n",
    "3. **Use `relationship` option** for relationship reads with source/target nodes\n",
    "4. **Enable partitions** for large result sets (disables limit pushdown)\n",
    "5. **Leverage pushdown** - filters, columns, aggregates, limits are pushed to Neo4j\n",
    "\n",
    "For more queries, see `DATA_IMPORT.md` in the project root."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}