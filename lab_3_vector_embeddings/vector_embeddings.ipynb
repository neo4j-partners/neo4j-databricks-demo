{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-0",
   "metadata": {},
   "source": [
    "# Lab 3: Vector Embeddings and Hybrid Search\n",
    "\n",
    "This notebook processes HTML documents from the Databricks volume, generates vector embeddings,\n",
    "stores them in Neo4j as a document graph, and enables hybrid search.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. **Neo4j database** running (Aura or self-hosted, version 5.11+)\n",
    "2. **Databricks Secrets** configured with `neo4j-creds` scope\n",
    "3. **Unity Catalog Volume** with HTML files (from Lab 1)\n",
    "4. **Lab 2 completed** - financial entity graph populated\n",
    "\n",
    "## Embedding Model\n",
    "\n",
    "Uses **Databricks Foundation Model** `databricks-gte-large-en` (1024 dimensions, 8K context).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header-1",
   "metadata": {},
   "source": [
    "## Step 1: Configuration\n",
    "\n",
    "Load secrets from Databricks and configure connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION - Load from Databricks Secrets\n",
    "# =============================================================================\n",
    "import time\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CONFIGURATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Retrieve credentials from Databricks Secrets\n",
    "NEO4J_URL = dbutils.secrets.get(scope=\"neo4j-creds\", key=\"url\")\n",
    "NEO4J_USER = dbutils.secrets.get(scope=\"neo4j-creds\", key=\"username\")\n",
    "NEO4J_PASS = dbutils.secrets.get(scope=\"neo4j-creds\", key=\"password\")\n",
    "VOLUME_PATH = dbutils.secrets.get(scope=\"neo4j-creds\", key=\"volume_path\")\n",
    "\n",
    "NEO4J_DATABASE = \"neo4j\"\n",
    "HTML_PATH = f\"{VOLUME_PATH}/html\"\n",
    "\n",
    "print(f\"Neo4j URL:  {NEO4J_URL}\")\n",
    "print(f\"HTML Path:  {HTML_PATH}\")\n",
    "print(\"[OK] Configuration loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header-3",
   "metadata": {},
   "source": [
    "## Step 2: Import Lab 3 Package\n",
    "\n",
    "Import models, processing functions, and search components from the lab package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS FROM LAB 3 PACKAGE\n",
    "# =============================================================================\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Models\n",
    "from lab_3_vector_embeddings.models import (\n",
    "    ChunkConfig,\n",
    "    EmbeddingConfig,\n",
    "    EmbeddingProvider,\n",
    "    IndexConfig,\n",
    "    Neo4jConfig,\n",
    ")\n",
    "\n",
    "# Processing\n",
    "from lab_3_vector_embeddings.processing import (\n",
    "    process_html_content,\n",
    "    chunk_document_sync,\n",
    ")\n",
    "\n",
    "# Embeddings\n",
    "from lab_3_vector_embeddings.embeddings import (\n",
    "    create_embedder,\n",
    "    embed_chunks,\n",
    "    get_default_config_for_provider,\n",
    ")\n",
    "\n",
    "# Graph writing\n",
    "from lab_3_vector_embeddings.graph import write_document_graph\n",
    "\n",
    "# Search\n",
    "from lab_3_vector_embeddings.search import create_searcher\n",
    "\n",
    "print(\"[OK] Lab 3 package imported\")\n",
    "print(\"  - Models: ChunkConfig, IndexConfig, Neo4jConfig, etc.\")\n",
    "print(\"  - Processing: process_html_content, chunk_document_sync\")\n",
    "print(\"  - Embeddings: create_embedder, embed_chunks\")\n",
    "print(\"  - Graph: write_document_graph\")\n",
    "print(\"  - Search: create_searcher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-objects-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# INITIALIZE CONFIGURATION OBJECTS\n",
    "# =============================================================================\n",
    "\n",
    "# Neo4j connection config\n",
    "neo4j_config = Neo4jConfig(\n",
    "    uri=NEO4J_URL,\n",
    "    username=NEO4J_USER,\n",
    "    password=NEO4J_PASS,\n",
    "    database=NEO4J_DATABASE,\n",
    ")\n",
    "\n",
    "# Chunking config (neo4j-graphrag FixedSizeSplitter settings)\n",
    "chunk_config = ChunkConfig(chunk_size=4000, chunk_overlap=200)\n",
    "\n",
    "# Index config\n",
    "index_config = IndexConfig()\n",
    "\n",
    "# Embedding config - Databricks GTE Large (1024 dims, 8K context)\n",
    "embedding_config = get_default_config_for_provider(EmbeddingProvider.DATABRICKS)\n",
    "\n",
    "print(\"[OK] Configuration objects created\")\n",
    "print(f\"  Chunk size: {chunk_config.chunk_size}, overlap: {chunk_config.chunk_overlap}\")\n",
    "print(f\"  Embedding: {embedding_config.model_name} ({embedding_config.dimensions} dims)\")\n",
    "print(f\"  Vector index: {index_config.vector_index_name}\")\n",
    "print(f\"  Fulltext index: {index_config.fulltext_index_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify-header-6",
   "metadata": {},
   "source": [
    "## Step 3: Verify Prerequisites\n",
    "\n",
    "Check Neo4j connectivity and HTML file availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VERIFY PREREQUISITES\n",
    "# =============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"PREREQUISITE VERIFICATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check HTML files\n",
    "print(f\"\\n[1] HTML Files in {HTML_PATH}:\")\n",
    "files = dbutils.fs.ls(HTML_PATH)\n",
    "html_files = [f for f in files if f.name.endswith('.html')]\n",
    "for f in html_files:\n",
    "    print(f\"    - {f.name}\")\n",
    "print(f\"    Total: {len(html_files)} files\")\n",
    "\n",
    "# Check Neo4j connection\n",
    "print(f\"\\n[2] Neo4j Connection:\")\n",
    "driver = GraphDatabase.driver(NEO4J_URL, auth=(NEO4J_USER, NEO4J_PASS))\n",
    "with driver.session(database=NEO4J_DATABASE) as session:\n",
    "    result = session.run(\"RETURN 1 AS test\")\n",
    "    result.single()\n",
    "print(f\"    [OK] Connected to {NEO4J_URL}\")\n",
    "\n",
    "# Check existing entity graph from Lab 2\n",
    "print(f\"\\n[3] Existing Entity Graph (from Lab 2):\")\n",
    "with driver.session(database=NEO4J_DATABASE) as session:\n",
    "    result = session.run(\"\"\"\n",
    "        MATCH (n) WHERE n:Customer OR n:Company OR n:Stock\n",
    "        RETURN labels(n)[0] AS label, count(n) AS count\n",
    "        ORDER BY label\n",
    "    \"\"\")\n",
    "    for record in result:\n",
    "        print(f\"    {record['label']}: {record['count']} nodes\")\n",
    "\n",
    "driver.close()\n",
    "print(\"\\n[OK] All prerequisites verified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "process-header-8",
   "metadata": {},
   "source": [
    "## Step 4: Process Documents\n",
    "\n",
    "Load HTML files, extract text, and create chunks using the `step1_process_documents` pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "process-docs-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 1: DOCUMENT PROCESSING\n",
    "# =============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 1: Document Processing\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "start_time = time.time()\n",
    "documents = []\n",
    "all_chunks = []\n",
    "\n",
    "for i, file_info in enumerate(html_files):\n",
    "    filename = file_info.name\n",
    "    filepath = f\"{HTML_PATH}/{filename}\"\n",
    "    \n",
    "    print(f\"  [{i+1}/{len(html_files)}] Processing: {filename}\")\n",
    "    \n",
    "    # Read HTML content from Databricks volume\n",
    "    content = dbutils.fs.head(filepath, 100000)\n",
    "    \n",
    "    # Process document using lab package\n",
    "    doc = process_html_content(content, filename, filepath)\n",
    "    documents.append(doc)\n",
    "    print(f\"           Type: {doc.document_type.value}, Chars: {len(doc.raw_text)}\")\n",
    "    \n",
    "    # Chunk document using lab package\n",
    "    chunks = chunk_document_sync(doc, chunk_config)\n",
    "    all_chunks.extend(chunks)\n",
    "    print(f\"           Chunks: {len(chunks)}\")\n",
    "\n",
    "doc_processing_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n  [OK] Processed {len(documents)} documents into {len(all_chunks)} chunks\")\n",
    "print(f\"       Time: {doc_processing_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embed-header-10",
   "metadata": {},
   "source": [
    "## Step 5: Generate Embeddings\n",
    "\n",
    "Create vector embeddings using the `step2_generate_embeddings` pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embeddings-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 2: EMBEDDING GENERATION\n",
    "# =============================================================================\n",
    "from lab_3_vector_embeddings.embeddings import validate_embeddings\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 2: Embedding Generation\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  Provider: {embedding_config.provider.value}\")\n",
    "print(f\"  Model: {embedding_config.model_name}\")\n",
    "print(f\"  Dimensions: {embedding_config.dimensions}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Create embedder using lab package\n",
    "embedder = create_embedder(embedding_config)\n",
    "print(f\"\\n  [OK] Embedder initialized\")\n",
    "\n",
    "# Generate embeddings using lab package\n",
    "print(f\"  Embedding {len(all_chunks)} chunks...\")\n",
    "embedded_chunks = embed_chunks(all_chunks, embedder)\n",
    "\n",
    "# Validate embeddings\n",
    "is_valid, errors = validate_embeddings(embedded_chunks, embedding_config.dimensions)\n",
    "if not is_valid:\n",
    "    print(f\"  [WARNING] Embedding validation errors: {errors[:5]}\")\n",
    "else:\n",
    "    print(f\"  [OK] All embeddings validated ({embedding_config.dimensions} dimensions)\")\n",
    "\n",
    "embedding_time = time.time() - start_time\n",
    "print(f\"       Time: {embedding_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "write-header-12",
   "metadata": {},
   "source": [
    "## Step 6: Write Document Graph to Neo4j\n",
    "\n",
    "Create indexes, constraints, nodes, and relationships using the `step3_write_to_neo4j` pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "write-graph-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 3: NEO4J GRAPH WRITING\n",
    "# =============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 3: Neo4j Graph Writing\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  URI: {neo4j_config.uri}\")\n",
    "print(f\"  Database: {neo4j_config.database}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Use the lab package's write_document_graph function\n",
    "# This handles: constraints, indexes, documents, chunks, and relationships\n",
    "graph_results = write_document_graph(\n",
    "    neo4j_config=neo4j_config,\n",
    "    documents=documents,\n",
    "    chunks=embedded_chunks,\n",
    "    embedding_dimensions=embedding_config.dimensions,\n",
    "    index_config=index_config,\n",
    "    clear_existing=False,  # Set True to clear existing document graph first\n",
    ")\n",
    "\n",
    "graph_writing_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n  [OK] Graph writing complete\")\n",
    "print(f\"       Documents written: {graph_results['documents'].get('documents_written', 0)}\")\n",
    "print(f\"       Chunks written: {graph_results['chunks'].get('chunks_written', 0)}\")\n",
    "print(f\"       FROM_DOCUMENT relationships: {graph_results['from_document'].get('from_document_relationships', 0)}\")\n",
    "print(f\"       NEXT_CHUNK relationships: {graph_results['next_chunk'].get('next_chunk_relationships', 0)}\")\n",
    "print(f\"       DESCRIBES relationships: {graph_results['describes'].get('describes_relationships', 0)}\")\n",
    "print(f\"       Time: {graph_writing_time:.2f}s\")\n",
    "\n",
    "print(\"\\n  Index Status:\")\n",
    "for name, status in graph_results.get('index_status', {}).items():\n",
    "    print(f\"    {name}: {status.get('state', 'unknown')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "search-header-14",
   "metadata": {},
   "source": [
    "## Step 7: Search Demonstrations\n",
    "\n",
    "Demonstrate vector, full-text, hybrid, and graph-aware search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "search-setup-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# INITIALIZE SEARCHER\n",
    "# =============================================================================\n",
    "\n",
    "# Create searcher using lab package\n",
    "searcher = create_searcher(neo4j_config, embedder, index_config)\n",
    "print(\"[OK] DocumentSearcher initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vector-search-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DEMO 1: VECTOR SEARCH\n",
    "# =============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"DEMO 1: Vector Search\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Query: 'investment strategies for moderate risk'\\n\")\n",
    "\n",
    "results = searcher.vector_search(\"investment strategies for moderate risk\")\n",
    "\n",
    "for i, r in enumerate(results[:3]):\n",
    "    print(f\"{i+1}. Score: {r.score:.4f}\")\n",
    "    print(f\"   Document: {r.document_title}\")\n",
    "    print(f\"   Text: {r.text[:150]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fulltext-search-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DEMO 2: FULL-TEXT SEARCH\n",
    "# =============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"DEMO 2: Full-Text Search\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Query: 'renewable energy'\\n\")\n",
    "\n",
    "results = searcher.fulltext_search(\"renewable energy\")\n",
    "\n",
    "for i, r in enumerate(results[:3]):\n",
    "    print(f\"{i+1}. Score: {r.score:.4f}\")\n",
    "    print(f\"   Document: {r.document_title}\")\n",
    "    print(f\"   Text: {r.text[:150]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-search-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DEMO 3: HYBRID SEARCH\n",
    "# =============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"DEMO 3: Hybrid Search\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Query: 'customer technology portfolio'\\n\")\n",
    "\n",
    "results = searcher.hybrid_search(\"customer technology portfolio\")\n",
    "\n",
    "for i, r in enumerate(results[:3]):\n",
    "    print(f\"{i+1}. Score: {r.score:.4f}\")\n",
    "    print(f\"   Document: {r.document_title}\")\n",
    "    print(f\"   Text: {r.text[:150]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graph-search-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DEMO 4: GRAPH-AWARE SEARCH\n",
    "# =============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"DEMO 4: Graph-Aware Search\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Query: 'retirement planning'\")\n",
    "print(\"Traverses: Chunk -> Document -> Customer\\n\")\n",
    "\n",
    "result = searcher.vector_search_with_graph_traversal(\"retirement planning\")\n",
    "\n",
    "print(f\"Found {len(result.search_results)} chunks\")\n",
    "print(f\"Related customers: {len(result.related_customers)}\")\n",
    "print(f\"Related companies: {len(result.related_companies)}\")\n",
    "print(f\"Related stocks: {len(result.related_stocks)}\")\n",
    "\n",
    "if result.related_customers:\n",
    "    print(\"\\nConnected Customers:\")\n",
    "    for c in result.related_customers[:5]:\n",
    "        name = f\"{c.get('first_name', '')} {c.get('last_name', '')}\".strip()\n",
    "        print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CLEANUP AND SUMMARY\n",
    "# =============================================================================\n",
    "searcher.close()\n",
    "print(\"[OK] Searcher closed\")\n",
    "\n",
    "# Pipeline Summary\n",
    "total_time = doc_processing_time + embedding_time + graph_writing_time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PIPELINE COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  Documents processed: {len(documents)}\")\n",
    "print(f\"  Chunks created: {len(all_chunks)}\")\n",
    "print(f\"  Total time: {total_time:.2f}s\")\n",
    "print(\"\\n  Timing breakdown:\")\n",
    "print(f\"    Document processing: {doc_processing_time:.2f}s\")\n",
    "print(f\"    Embedding generation: {embedding_time:.2f}s\")\n",
    "print(f\"    Graph writing: {graph_writing_time:.2f}s\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-21",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Lab 3 demonstrated:\n",
    "\n",
    "1. **Document Processing** - HTML parsing and chunking via `process_html_content()` and `chunk_document_sync()`\n",
    "2. **Embedding Generation** - Databricks `databricks-gte-large-en` model (1024 dims) via `create_embedder()`\n",
    "3. **Graph Storage** - Document/Chunk nodes with relationships via `write_document_graph()`\n",
    "4. **Search Capabilities** via `DocumentSearcher`:\n",
    "   - `vector_search()` - Semantic similarity\n",
    "   - `fulltext_search()` - Keyword matching\n",
    "   - `hybrid_search()` - Combined vector + keyword\n",
    "   - `vector_search_with_graph_traversal()` - Graph-aware retrieval\n",
    "\n",
    "### Package Structure\n",
    "\n",
    "```\n",
    "lab_3_vector_embeddings/\n",
    "├── models/      # Pydantic models (Neo4jConfig, ChunkConfig, etc.)\n",
    "├── processing/  # Document processing (HTML parsing, chunking)\n",
    "├── embeddings/  # Embedding providers (Databricks, SentenceTransformers)\n",
    "├── graph/       # Neo4j graph writing\n",
    "└── search/      # Search implementations\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
