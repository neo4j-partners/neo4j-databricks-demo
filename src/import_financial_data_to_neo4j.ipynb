{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Demo Data Import to Neo4j\n",
    "\n",
    "This notebook imports the retail banking and investment portfolio demonstration data from Databricks Unity Catalog into Neo4j.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. **Neo4j database** running (Aura or self-hosted)\n",
    "2. **Databricks Secrets** configured with `neo4j-creds` scope containing `username`, `password`, and `url`\n",
    "3. **Unity Catalog Volume** with CSV files uploaded\n",
    "4. **Databricks Cluster** with Neo4j Spark Connector installed\n",
    "\n",
    "## Data Overview\n",
    "\n",
    "- **102 Customers** with demographics and financial profiles\n",
    "- **102 Banks** across multiple types (commercial, regional, community)\n",
    "- **123 Accounts** (checking, savings, investment)\n",
    "- **102 Companies** across 12+ sectors\n",
    "- **102 Stocks** with market data\n",
    "- **110 Portfolio Positions** linking accounts to stocks\n",
    "- **123 Transactions** between accounts\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Configuration\n",
    "\n",
    "Configure Neo4j connection and data source paths. All credentials are retrieved from Databricks Secrets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Retrieve Neo4j credentials from Databricks Secrets\n",
    "NEO4J_USER = dbutils.secrets.get(scope=\"neo4j-creds\", key=\"username\")\n",
    "NEO4J_PASS = dbutils.secrets.get(scope=\"neo4j-creds\", key=\"password\")\n",
    "NEO4J_URL = dbutils.secrets.get(scope=\"neo4j-creds\", key=\"url\")\n",
    "\n",
    "# Unity Catalog Volume path containing CSV files\n",
    "VOLUME_PATH = dbutils.secrets.get(scope=\"neo4j-creds\", key=\"volume_path\")\n",
    "\n",
    "# Neo4j database name (default: neo4j)\n",
    "NEO4J_DATABASE = \"neo4j\"\n",
    "\n",
    "# Configure Spark session for Neo4j connector\n",
    "spark.conf.set(\"neo4j.url\", NEO4J_URL)\n",
    "spark.conf.set(\"neo4j.authentication.basic.username\", NEO4J_USER)\n",
    "spark.conf.set(\"neo4j.authentication.basic.password\", NEO4J_PASS)\n",
    "spark.conf.set(\"neo4j.database\", NEO4J_DATABASE)\n",
    "\n",
    "print(f\"Neo4j URL: {NEO4J_URL}\")\n",
    "print(f\"Database: {NEO4J_DATABASE}\")\n",
    "print(f\"Volume Path: {VOLUME_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Verify Prerequisites\n",
    "\n",
    "Verify Neo4j connectivity and CSV file availability before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify CSV files exist in Unity Catalog Volume\n",
    "print(\"Checking CSV files in Unity Catalog Volume...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "expected_files = [\n",
    "    \"customers.csv\",\n",
    "    \"banks.csv\",\n",
    "    \"accounts.csv\",\n",
    "    \"companies.csv\",\n",
    "    \"stocks.csv\",\n",
    "    \"portfolio_holdings.csv\",\n",
    "    \"transactions.csv\"\n",
    "]\n",
    "\n",
    "files = dbutils.fs.ls(VOLUME_PATH)\n",
    "found_files = [f.name for f in files]\n",
    "\n",
    "all_present = True\n",
    "for expected in expected_files:\n",
    "    status = \"FOUND\" if expected in found_files else \"MISSING\"\n",
    "    if status == \"MISSING\":\n",
    "        all_present = False\n",
    "    print(f\"  {expected}: {status}\")\n",
    "\n",
    "if all_present:\n",
    "    print(\"\\nAll required CSV files are present.\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"Missing required CSV files. Please upload all files to the Unity Catalog Volume.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Neo4j connectivity\n",
    "print(\"Testing Neo4j connection...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    test_df = (\n",
    "        spark.read.format(\"org.neo4j.spark.DataSource\")\n",
    "        .option(\"url\", NEO4J_URL)\n",
    "        .option(\"authentication.basic.username\", NEO4J_USER)\n",
    "        .option(\"authentication.basic.password\", NEO4J_PASS)\n",
    "        .option(\"database\", NEO4J_DATABASE)\n",
    "        .option(\"query\", \"RETURN 'Connected' AS status\")\n",
    "        .load()\n",
    "    )\n",
    "    test_df.show()\n",
    "    print(\"Neo4j connection successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {str(e)}\")\n",
    "    print(\"\\nPlease verify:\")\n",
    "    print(\"  1. Neo4j database is running\")\n",
    "    print(\"  2. Connection URL is correct\")\n",
    "    print(\"  3. Credentials are valid\")\n",
    "    print(\"  4. Network connectivity is available\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Helper Functions\n",
    "\n",
    "Define reusable functions for data loading and Neo4j operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType, IntegerType, DateType\n",
    "\n",
    "\n",
    "def read_csv(filename: str) -> DataFrame:\n",
    "    \"\"\"Read a CSV file from the Unity Catalog Volume.\"\"\"\n",
    "    path = f\"{VOLUME_PATH}/{filename}\"\n",
    "    return spark.read.option(\"header\", \"true\").csv(path)\n",
    "\n",
    "\n",
    "def write_nodes(df: DataFrame, label: str, node_key: str) -> None:\n",
    "    \"\"\"Write DataFrame rows as nodes to Neo4j.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing node properties\n",
    "        label: Neo4j node label\n",
    "        node_key: Property name to use as the node key\n",
    "    \"\"\"\n",
    "    (\n",
    "        df.write.format(\"org.neo4j.spark.DataSource\")\n",
    "        .mode(\"Append\")\n",
    "        .option(\"labels\", f\":{label}\")\n",
    "        .option(\"node.keys\", node_key)\n",
    "        .save()\n",
    "    )\n",
    "\n",
    "\n",
    "def write_relationship(\n",
    "    df: DataFrame,\n",
    "    rel_type: str,\n",
    "    source_label: str,\n",
    "    source_key: str,\n",
    "    target_label: str,\n",
    "    target_key: str\n",
    ") -> None:\n",
    "    \"\"\"Write DataFrame rows as relationships to Neo4j using key matching.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with source and target key columns\n",
    "        rel_type: Neo4j relationship type\n",
    "        source_label: Source node label\n",
    "        source_key: Source node key column name\n",
    "        target_label: Target node label\n",
    "        target_key: Target node key column name\n",
    "    \"\"\"\n",
    "    (\n",
    "        df.write.format(\"org.neo4j.spark.DataSource\")\n",
    "        .mode(\"Append\")\n",
    "        .option(\"relationship\", rel_type)\n",
    "        .option(\"relationship.save.strategy\", \"keys\")\n",
    "        .option(\"relationship.source.save.mode\", \"Match\")\n",
    "        .option(\"relationship.source.labels\", f\":{source_label}\")\n",
    "        .option(\"relationship.source.node.keys\", f\"{source_key}:{source_key}\")\n",
    "        .option(\"relationship.target.save.mode\", \"Match\")\n",
    "        .option(\"relationship.target.labels\", f\":{target_label}\")\n",
    "        .option(\"relationship.target.node.keys\", f\"{target_key}:{target_key}\")\n",
    "        .save()\n",
    "    )\n",
    "\n",
    "\n",
    "def run_cypher(query: str) -> DataFrame:\n",
    "    \"\"\"Execute a Cypher query and return results as DataFrame.\"\"\"\n",
    "    return (\n",
    "        spark.read.format(\"org.neo4j.spark.DataSource\")\n",
    "        .option(\"url\", NEO4J_URL)\n",
    "        .option(\"authentication.basic.username\", NEO4J_USER)\n",
    "        .option(\"authentication.basic.password\", NEO4J_PASS)\n",
    "        .option(\"database\", NEO4J_DATABASE)\n",
    "        .option(\"query\", query)\n",
    "        .load()\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load and Transform CSV Data\n",
    "\n",
    "Load all CSV files and apply appropriate data type conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading CSV files from Unity Catalog Volume...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load raw CSVs\n",
    "customers_raw = read_csv(\"customers.csv\")\n",
    "banks_raw = read_csv(\"banks.csv\")\n",
    "accounts_raw = read_csv(\"accounts.csv\")\n",
    "companies_raw = read_csv(\"companies.csv\")\n",
    "stocks_raw = read_csv(\"stocks.csv\")\n",
    "positions_raw = read_csv(\"portfolio_holdings.csv\")\n",
    "transactions_raw = read_csv(\"transactions.csv\")\n",
    "\n",
    "print(f\"  customers.csv: {customers_raw.count()} rows\")\n",
    "print(f\"  banks.csv: {banks_raw.count()} rows\")\n",
    "print(f\"  accounts.csv: {accounts_raw.count()} rows\")\n",
    "print(f\"  companies.csv: {companies_raw.count()} rows\")\n",
    "print(f\"  stocks.csv: {stocks_raw.count()} rows\")\n",
    "print(f\"  portfolio_holdings.csv: {positions_raw.count()} rows\")\n",
    "print(f\"  transactions.csv: {transactions_raw.count()} rows\")\n",
    "\n",
    "print(\"\\nAll CSV files loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Applying data type conversions...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Transform Customers\n",
    "customers = (\n",
    "    customers_raw\n",
    "    .withColumn(\"annual_income\", F.col(\"annual_income\").cast(IntegerType()))\n",
    "    .withColumn(\"credit_score\", F.col(\"credit_score\").cast(IntegerType()))\n",
    "    .withColumn(\"registration_date\", F.to_date(F.col(\"registration_date\")))\n",
    "    .withColumn(\"date_of_birth\", F.to_date(F.col(\"date_of_birth\")))\n",
    ")\n",
    "print(\"  Customers: annual_income (INT), credit_score (INT), dates (DATE)\")\n",
    "\n",
    "# Transform Banks\n",
    "banks = (\n",
    "    banks_raw\n",
    "    .withColumn(\"total_assets_billions\", F.col(\"total_assets_billions\").cast(DoubleType()))\n",
    "    .withColumn(\"established_year\", F.col(\"established_year\").cast(IntegerType()))\n",
    ")\n",
    "print(\"  Banks: total_assets_billions (DOUBLE), established_year (INT)\")\n",
    "\n",
    "# Transform Accounts\n",
    "accounts = (\n",
    "    accounts_raw\n",
    "    .withColumn(\"balance\", F.col(\"balance\").cast(DoubleType()))\n",
    "    .withColumn(\"interest_rate\", F.col(\"interest_rate\").cast(DoubleType()))\n",
    "    .withColumn(\"opened_date\", F.to_date(F.col(\"opened_date\")))\n",
    ")\n",
    "print(\"  Accounts: balance (DOUBLE), interest_rate (DOUBLE), opened_date (DATE)\")\n",
    "\n",
    "# Transform Companies\n",
    "companies = (\n",
    "    companies_raw\n",
    "    .withColumn(\"market_cap_billions\", F.col(\"market_cap_billions\").cast(DoubleType()))\n",
    "    .withColumn(\"annual_revenue_billions\", F.col(\"annual_revenue_billions\").cast(DoubleType()))\n",
    "    .withColumn(\"founded_year\", F.col(\"founded_year\").cast(IntegerType()))\n",
    "    .withColumn(\"employee_count\", F.col(\"employee_count\").cast(IntegerType()))\n",
    ")\n",
    "print(\"  Companies: market_cap (DOUBLE), revenue (DOUBLE), founded_year (INT), employees (INT)\")\n",
    "\n",
    "# Transform Stocks\n",
    "stocks = (\n",
    "    stocks_raw\n",
    "    .withColumn(\"current_price\", F.col(\"current_price\").cast(DoubleType()))\n",
    "    .withColumn(\"previous_close\", F.col(\"previous_close\").cast(DoubleType()))\n",
    "    .withColumn(\"opening_price\", F.col(\"opening_price\").cast(DoubleType()))\n",
    "    .withColumn(\"day_high\", F.col(\"day_high\").cast(DoubleType()))\n",
    "    .withColumn(\"day_low\", F.col(\"day_low\").cast(DoubleType()))\n",
    "    .withColumn(\"volume\", F.col(\"volume\").cast(IntegerType()))\n",
    "    .withColumn(\"market_cap_billions\", F.col(\"market_cap_billions\").cast(DoubleType()))\n",
    "    .withColumn(\"pe_ratio\", F.col(\"pe_ratio\").cast(DoubleType()))\n",
    "    .withColumn(\"dividend_yield\", F.col(\"dividend_yield\").cast(DoubleType()))\n",
    "    .withColumn(\"fifty_two_week_high\", F.col(\"fifty_two_week_high\").cast(DoubleType()))\n",
    "    .withColumn(\"fifty_two_week_low\", F.col(\"fifty_two_week_low\").cast(DoubleType()))\n",
    ")\n",
    "print(\"  Stocks: all price/ratio fields (DOUBLE), volume (INT)\")\n",
    "\n",
    "# Transform Positions (rename holding_id to position_id for clarity)\n",
    "positions = (\n",
    "    positions_raw\n",
    "    .withColumnRenamed(\"holding_id\", \"position_id\")\n",
    "    .withColumn(\"shares\", F.col(\"shares\").cast(IntegerType()))\n",
    "    .withColumn(\"purchase_price\", F.col(\"purchase_price\").cast(DoubleType()))\n",
    "    .withColumn(\"current_value\", F.col(\"current_value\").cast(DoubleType()))\n",
    "    .withColumn(\"percentage_of_portfolio\", F.col(\"percentage_of_portfolio\").cast(DoubleType()))\n",
    "    .withColumn(\"purchase_date\", F.to_date(F.col(\"purchase_date\")))\n",
    ")\n",
    "print(\"  Positions: shares (INT), prices/values (DOUBLE), purchase_date (DATE)\")\n",
    "\n",
    "# Transform Transactions\n",
    "transactions = (\n",
    "    transactions_raw\n",
    "    .withColumn(\"amount\", F.col(\"amount\").cast(DoubleType()))\n",
    "    .withColumn(\"transaction_date\", F.to_date(F.col(\"transaction_date\")))\n",
    ")\n",
    "print(\"  Transactions: amount (DOUBLE), transaction_date (DATE)\")\n",
    "\n",
    "print(\"\\nData type conversions complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Indexes and Constraints\n",
    "\n",
    "Create indexes and uniqueness constraints BEFORE loading data for optimal performance.\n",
    "\n",
    "**Best Practice**: Creating indexes first significantly improves write performance for large datasets and ensures data integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating indexes and constraints in Neo4j...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Define constraints and indexes\n",
    "constraints = [\n",
    "    (\"customer_id_unique\", \"Customer\", \"customer_id\"),\n",
    "    (\"bank_id_unique\", \"Bank\", \"bank_id\"),\n",
    "    (\"account_id_unique\", \"Account\", \"account_id\"),\n",
    "    (\"company_id_unique\", \"Company\", \"company_id\"),\n",
    "    (\"stock_id_unique\", \"Stock\", \"stock_id\"),\n",
    "    (\"position_id_unique\", \"Position\", \"position_id\"),\n",
    "    (\"transaction_id_unique\", \"Transaction\", \"transaction_id\"),\n",
    "]\n",
    "\n",
    "for constraint_name, label, property_name in constraints:\n",
    "    query = f\"\"\"\n",
    "    CREATE CONSTRAINT {constraint_name} IF NOT EXISTS\n",
    "    FOR (n:{label})\n",
    "    REQUIRE n.{property_name} IS UNIQUE\n",
    "    \"\"\"\n",
    "    try:\n",
    "        run_cypher(query).collect()\n",
    "        print(f\"  Constraint: {constraint_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Constraint {constraint_name}: {str(e)[:50]}...\")\n",
    "\n",
    "print(\"\\nConstraints and indexes created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Write Nodes to Neo4j\n",
    "\n",
    "Write all node types to Neo4j. The order doesn't matter since we're creating nodes first, then relationships.\n",
    "\n",
    "**Graph Schema:**\n",
    "- Customer (102 nodes)\n",
    "- Bank (102 nodes)\n",
    "- Account (123 nodes)\n",
    "- Company (102 nodes)\n",
    "- Stock (102 nodes)\n",
    "- Position (110 nodes)\n",
    "- Transaction (123 nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Writing nodes to Neo4j...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Customer nodes\n",
    "print(\"\\n[1/7] Writing Customer nodes...\")\n",
    "write_nodes(customers, \"Customer\", \"customer_id\")\n",
    "print(f\"       {customers.count()} Customer nodes written\")\n",
    "\n",
    "# Bank nodes\n",
    "print(\"\\n[2/7] Writing Bank nodes...\")\n",
    "write_nodes(banks, \"Bank\", \"bank_id\")\n",
    "print(f\"       {banks.count()} Bank nodes written\")\n",
    "\n",
    "# Account nodes (exclude foreign keys, we'll create relationships)\n",
    "print(\"\\n[3/7] Writing Account nodes...\")\n",
    "account_props = accounts.select(\n",
    "    \"account_id\", \"account_number\", \"account_type\", \n",
    "    \"balance\", \"currency\", \"opened_date\", \"status\", \"interest_rate\"\n",
    ")\n",
    "write_nodes(account_props, \"Account\", \"account_id\")\n",
    "print(f\"       {account_props.count()} Account nodes written\")\n",
    "\n",
    "# Company nodes\n",
    "print(\"\\n[4/7] Writing Company nodes...\")\n",
    "write_nodes(companies, \"Company\", \"company_id\")\n",
    "print(f\"       {companies.count()} Company nodes written\")\n",
    "\n",
    "# Stock nodes (exclude foreign key)\n",
    "print(\"\\n[5/7] Writing Stock nodes...\")\n",
    "stock_props = stocks.select(\n",
    "    \"stock_id\", \"ticker\", \"current_price\", \"previous_close\", \"opening_price\",\n",
    "    \"day_high\", \"day_low\", \"volume\", \"market_cap_billions\", \"pe_ratio\",\n",
    "    \"dividend_yield\", \"fifty_two_week_high\", \"fifty_two_week_low\", \"exchange\"\n",
    ")\n",
    "write_nodes(stock_props, \"Stock\", \"stock_id\")\n",
    "print(f\"       {stock_props.count()} Stock nodes written\")\n",
    "\n",
    "# Position nodes (exclude foreign keys)\n",
    "print(\"\\n[6/7] Writing Position nodes...\")\n",
    "position_props = positions.select(\n",
    "    \"position_id\", \"shares\", \"purchase_price\", \"purchase_date\",\n",
    "    \"current_value\", \"percentage_of_portfolio\"\n",
    ")\n",
    "write_nodes(position_props, \"Position\", \"position_id\")\n",
    "print(f\"       {position_props.count()} Position nodes written\")\n",
    "\n",
    "# Transaction nodes (exclude foreign keys)\n",
    "print(\"\\n[7/7] Writing Transaction nodes...\")\n",
    "transaction_props = transactions.select(\n",
    "    \"transaction_id\", \"amount\", \"currency\", \"transaction_date\",\n",
    "    \"transaction_time\", \"type\", \"status\", \"description\"\n",
    ")\n",
    "write_nodes(transaction_props, \"Transaction\", \"transaction_id\")\n",
    "print(f\"       {transaction_props.count()} Transaction nodes written\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ALL NODES WRITTEN SUCCESSFULLY!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Write Relationships to Neo4j\n",
    "\n",
    "Create all relationships between nodes using key matching.\n",
    "\n",
    "**Relationship Types:**\n",
    "1. `(:Customer)-[:HAS_ACCOUNT]->(:Account)` - Customer owns account\n",
    "2. `(:Account)-[:AT_BANK]->(:Bank)` - Account held at bank\n",
    "3. `(:Stock)-[:OF_COMPANY]->(:Company)` - Stock issued by company\n",
    "4. `(:Account)-[:PERFORMS]->(:Transaction)` - Account initiates transfer\n",
    "5. `(:Transaction)-[:BENEFITS_TO]->(:Account)` - Account receives funds\n",
    "6. `(:Account)-[:HAS_POSITION]->(:Position)` - Account holds position\n",
    "7. `(:Position)-[:OF_SECURITY]->(:Stock)` - Position is in specific stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Writing relationships to Neo4j...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. HAS_ACCOUNT: Customer -> Account\n",
    "print(\"\\n[1/7] Writing HAS_ACCOUNT relationships...\")\n",
    "has_account_df = accounts.select(\"customer_id\", \"account_id\")\n",
    "write_relationship(\n",
    "    has_account_df, \"HAS_ACCOUNT\",\n",
    "    \"Customer\", \"customer_id\",\n",
    "    \"Account\", \"account_id\"\n",
    ")\n",
    "print(f\"       {has_account_df.count()} HAS_ACCOUNT relationships written\")\n",
    "\n",
    "# 2. AT_BANK: Account -> Bank\n",
    "print(\"\\n[2/7] Writing AT_BANK relationships...\")\n",
    "at_bank_df = accounts.select(\"account_id\", \"bank_id\")\n",
    "write_relationship(\n",
    "    at_bank_df, \"AT_BANK\",\n",
    "    \"Account\", \"account_id\",\n",
    "    \"Bank\", \"bank_id\"\n",
    ")\n",
    "print(f\"       {at_bank_df.count()} AT_BANK relationships written\")\n",
    "\n",
    "# 3. OF_COMPANY: Stock -> Company\n",
    "print(\"\\n[3/7] Writing OF_COMPANY relationships...\")\n",
    "of_company_df = stocks.select(\"stock_id\", \"company_id\")\n",
    "write_relationship(\n",
    "    of_company_df, \"OF_COMPANY\",\n",
    "    \"Stock\", \"stock_id\",\n",
    "    \"Company\", \"company_id\"\n",
    ")\n",
    "print(f\"       {of_company_df.count()} OF_COMPANY relationships written\")\n",
    "\n",
    "# 4. PERFORMS: Account -> Transaction (from_account initiates)\n",
    "print(\"\\n[4/7] Writing PERFORMS relationships...\")\n",
    "performs_df = transactions.select(\n",
    "    F.col(\"from_account_id\").alias(\"account_id\"),\n",
    "    \"transaction_id\"\n",
    ")\n",
    "write_relationship(\n",
    "    performs_df, \"PERFORMS\",\n",
    "    \"Account\", \"account_id\",\n",
    "    \"Transaction\", \"transaction_id\"\n",
    ")\n",
    "print(f\"       {performs_df.count()} PERFORMS relationships written\")\n",
    "\n",
    "# 5. BENEFITS_TO: Transaction -> Account (to_account receives)\n",
    "print(\"\\n[5/7] Writing BENEFITS_TO relationships...\")\n",
    "benefits_df = transactions.select(\n",
    "    \"transaction_id\",\n",
    "    F.col(\"to_account_id\").alias(\"account_id\")\n",
    ")\n",
    "write_relationship(\n",
    "    benefits_df, \"BENEFITS_TO\",\n",
    "    \"Transaction\", \"transaction_id\",\n",
    "    \"Account\", \"account_id\"\n",
    ")\n",
    "print(f\"       {benefits_df.count()} BENEFITS_TO relationships written\")\n",
    "\n",
    "# 6. HAS_POSITION: Account -> Position\n",
    "print(\"\\n[6/7] Writing HAS_POSITION relationships...\")\n",
    "has_position_df = positions.select(\"account_id\", \"position_id\")\n",
    "write_relationship(\n",
    "    has_position_df, \"HAS_POSITION\",\n",
    "    \"Account\", \"account_id\",\n",
    "    \"Position\", \"position_id\"\n",
    ")\n",
    "print(f\"       {has_position_df.count()} HAS_POSITION relationships written\")\n",
    "\n",
    "# 7. OF_SECURITY: Position -> Stock\n",
    "print(\"\\n[7/7] Writing OF_SECURITY relationships...\")\n",
    "of_security_df = positions.select(\"position_id\", \"stock_id\")\n",
    "write_relationship(\n",
    "    of_security_df, \"OF_SECURITY\",\n",
    "    \"Position\", \"position_id\",\n",
    "    \"Stock\", \"stock_id\"\n",
    ")\n",
    "print(f\"       {of_security_df.count()} OF_SECURITY relationships written\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ALL RELATIONSHIPS WRITTEN SUCCESSFULLY!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Validate Import\n",
    "\n",
    "Run validation queries to verify the import completed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validating node counts...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Expected counts\n",
    "expected_nodes = {\n",
    "    \"Customer\": 102,\n",
    "    \"Bank\": 102,\n",
    "    \"Account\": 123,\n",
    "    \"Company\": 102,\n",
    "    \"Stock\": 102,\n",
    "    \"Position\": 110,\n",
    "    \"Transaction\": 123\n",
    "}\n",
    "\n",
    "# Query actual counts\n",
    "node_count_query = \"\"\"\n",
    "MATCH (n)\n",
    "RETURN labels(n)[0] AS label, count(n) AS count\n",
    "ORDER BY label\n",
    "\"\"\"\n",
    "node_counts = run_cypher(node_count_query).collect()\n",
    "\n",
    "print(\"\\n{:<15} {:>10} {:>10} {:>10}\".format(\"Label\", \"Expected\", \"Actual\", \"Status\"))\n",
    "print(\"-\" * 50)\n",
    "\n",
    "all_valid = True\n",
    "for row in node_counts:\n",
    "    label = row[\"label\"]\n",
    "    actual = row[\"count\"]\n",
    "    expected = expected_nodes.get(label, \"N/A\")\n",
    "    status = \"OK\" if actual == expected else \"MISMATCH\"\n",
    "    if status == \"MISMATCH\":\n",
    "        all_valid = False\n",
    "    print(\"{:<15} {:>10} {:>10} {:>10}\".format(label, expected, actual, status))\n",
    "\n",
    "if all_valid:\n",
    "    print(\"\\nNode validation: PASSED\")\n",
    "else:\n",
    "    print(\"\\nNode validation: FAILED - check mismatched counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validating relationship counts...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Expected counts\n",
    "expected_rels = {\n",
    "    \"HAS_ACCOUNT\": 123,\n",
    "    \"AT_BANK\": 123,\n",
    "    \"OF_COMPANY\": 102,\n",
    "    \"PERFORMS\": 123,\n",
    "    \"BENEFITS_TO\": 123,\n",
    "    \"HAS_POSITION\": 110,\n",
    "    \"OF_SECURITY\": 110\n",
    "}\n",
    "\n",
    "# Query actual counts\n",
    "rel_count_query = \"\"\"\n",
    "MATCH ()-[r]->()\n",
    "RETURN type(r) AS relationship_type, count(r) AS count\n",
    "ORDER BY relationship_type\n",
    "\"\"\"\n",
    "rel_counts = run_cypher(rel_count_query).collect()\n",
    "\n",
    "print(\"\\n{:<20} {:>10} {:>10} {:>10}\".format(\"Relationship\", \"Expected\", \"Actual\", \"Status\"))\n",
    "print(\"-\" * 55)\n",
    "\n",
    "all_valid = True\n",
    "for row in rel_counts:\n",
    "    rel_type = row[\"relationship_type\"]\n",
    "    actual = row[\"count\"]\n",
    "    expected = expected_rels.get(rel_type, \"N/A\")\n",
    "    status = \"OK\" if actual == expected else \"MISMATCH\"\n",
    "    if status == \"MISMATCH\":\n",
    "        all_valid = False\n",
    "    print(\"{:<20} {:>10} {:>10} {:>10}\".format(rel_type, expected, actual, status))\n",
    "\n",
    "if all_valid:\n",
    "    print(\"\\nRelationship validation: PASSED\")\n",
    "else:\n",
    "    print(\"\\nRelationship validation: FAILED - check mismatched counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running sample queries to verify data integrity...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Sample query 1: Customer's complete financial profile\n",
    "print(\"\\n[Query 1] Customer C0001's complete financial profile:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "query1 = \"\"\"\n",
    "MATCH (c:Customer {customer_id: 'C0001'})-[:HAS_ACCOUNT]->(a:Account)\n",
    "OPTIONAL MATCH (a)-[:AT_BANK]->(b:Bank)\n",
    "OPTIONAL MATCH (a)-[:HAS_POSITION]->(p:Position)-[:OF_SECURITY]->(s:Stock)\n",
    "RETURN\n",
    "    c.first_name + ' ' + c.last_name AS customer_name,\n",
    "    a.account_id AS account,\n",
    "    a.account_type AS account_type,\n",
    "    a.balance AS balance,\n",
    "    b.name AS bank_name,\n",
    "    s.ticker AS ticker,\n",
    "    p.shares AS shares,\n",
    "    p.current_value AS holding_value\n",
    "ORDER BY holding_value DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "display(run_cypher(query1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample query 2: Top 5 banks by total deposits\n",
    "print(\"\\n[Query 2] Top 5 banks by total deposits:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "query2 = \"\"\"\n",
    "MATCH (b:Bank)<-[:AT_BANK]-(a:Account)\n",
    "RETURN\n",
    "    b.name AS bank_name,\n",
    "    b.bank_type AS bank_type,\n",
    "    count(DISTINCT a) AS num_accounts,\n",
    "    round(sum(a.balance), 2) AS total_deposits\n",
    "ORDER BY total_deposits DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "display(run_cypher(query2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample query 3: Transaction flow validation\n",
    "print(\"\\n[Query 3] Recent transaction flow:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "query3 = \"\"\"\n",
    "MATCH (from:Account)-[:PERFORMS]->(t:Transaction)-[:BENEFITS_TO]->(to:Account)\n",
    "RETURN\n",
    "    from.account_id AS from_account,\n",
    "    t.transaction_id AS transaction_id,\n",
    "    t.amount AS amount,\n",
    "    t.transaction_date AS date,\n",
    "    to.account_id AS to_account\n",
    "ORDER BY t.transaction_date DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "display(run_cypher(query3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample query 4: Most popular stocks\n",
    "print(\"\\n[Query 4] Most widely held stocks:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "query4 = \"\"\"\n",
    "MATCH (a:Account)-[:HAS_POSITION]->(p:Position)-[:OF_SECURITY]->(s:Stock)-[:OF_COMPANY]->(c:Company)\n",
    "RETURN\n",
    "    c.name AS company_name,\n",
    "    s.ticker AS ticker,\n",
    "    count(DISTINCT a) AS num_holders,\n",
    "    sum(p.shares) AS total_shares_held,\n",
    "    round(sum(p.current_value), 2) AS total_market_value\n",
    "ORDER BY num_holders DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "display(run_cypher(query4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Complete\n",
    "\n",
    "The financial demo data has been successfully imported to Neo4j!\n",
    "\n",
    "### Summary\n",
    "\n",
    "**Nodes Created:**\n",
    "- 102 Customers\n",
    "- 102 Banks\n",
    "- 123 Accounts\n",
    "- 102 Companies\n",
    "- 102 Stocks\n",
    "- 110 Positions\n",
    "- 123 Transactions\n",
    "\n",
    "**Relationships Created:**\n",
    "- 123 HAS_ACCOUNT (Customer -> Account)\n",
    "- 123 AT_BANK (Account -> Bank)\n",
    "- 102 OF_COMPANY (Stock -> Company)\n",
    "- 123 PERFORMS (Account -> Transaction)\n",
    "- 123 BENEFITS_TO (Transaction -> Account)\n",
    "- 110 HAS_POSITION (Account -> Position)\n",
    "- 110 OF_SECURITY (Position -> Stock)\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Explore with Neo4j Browser** - Visualize the graph\n",
    "2. **Run Graph Algorithms** - PageRank, Community Detection\n",
    "3. **Build Applications** - Portfolio dashboards, risk analysis\n",
    "4. **Extend the Schema** - Add Advisors, Branches, Products\n",
    "\n",
    "---\n",
    "\n",
    "See `DATA_IMPORT.md` for additional query examples and use cases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
